{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> 2. Point Clouds Segmentation with Deep Learning </font> \n",
    "- Introduction\n",
    "- Network Architecture\n",
    "- Hands-on-Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'black'> 2.1 Introduction <font>\n",
    "\n",
    "<font color = 'black'> Point Cloud is an important geometrical datatype that is canonical (depth, lidar) but irregular. Due to its irregularity, most research works focus on transforming the point cloud data to regular 3D voxel grids (3D-CNN) or collections of images (2D-CNN). However, such transformation leads to various issues, and it becomes voluminous. The point cloud transformation may lead to losing the basic structure (or features) of point cloud data. </font> \n",
    "\n",
    "<font color = 'black'> To end this, PointNet was proposed in 2017 that focuses on learning a model on raw point cloud data. The network is the first one in this area, and basic but it is robust to perturbation and corruption. It is efficient and effective in many point cloud tasks such as object classification, part segmentation and semantic segmentation. \n",
    "\n",
    "In the following, we will see semantic segmentation with this method using the S3DIS dataset.  It is possible to extend this method it to any custom dataset.\n",
    "\n",
    "For further details, the article is available at: https://arxiv.org/abs/1612.00593 \n",
    "\n",
    "Reference: Qi, Charles R., et al. \"Pointnet: Deep learning on point sets for 3d classification and segmentation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Network Architecture: PointNet\n",
    "<img src=\"../../description/pointnet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Hands-on-Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from utilities.data_provide import rotate_point_cloud_z\n",
    "from dataloaders.S3DISDataLoader import S3DISDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes in list for S3DIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase',\n",
    "           'board', 'clutter']\n",
    "class2label = {cls: i for i, cls in enumerate(classes)}\n",
    "seg_classes = class2label\n",
    "seg_label_to_cat = {}\n",
    "for i, cat in enumerate(seg_classes.keys()):\n",
    "    seg_label_to_cat[i] = cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'> Parameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''PARAMETERS'''\n",
    "    gpu='0'\n",
    "    batch_size = 16\n",
    "    model='pointnet_sem_seg'\n",
    "    epoch=32\n",
    "    learning_rate=0.001\n",
    "    num_point=1024\n",
    "    optimizer='Adam'\n",
    "    log_dir = 'runs'\n",
    "    decay_rate=1e-4\n",
    "    npoint = 4096\n",
    "    step_size =10\n",
    "    lr_decay = 0.7\n",
    "    test_area=5\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace Relu saves memory!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace_relu(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('ReLU') != -1:\n",
    "        m.inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Function for the test dataloader. Used inside the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):    \n",
    "    num_batches = len(loader)\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    labelweights = np.zeros(NUM_CLASSES)\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_iou_deno_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    classifier = model.eval()\n",
    "\n",
    "    print('---- EPOCH %03d EVALUATION ----' % (global_epoch + 1))\n",
    "    for i, (points, target) in tqdm(enumerate(loader), total=len(loader), smoothing=0.9):\n",
    "        points = points.data.numpy()\n",
    "        points = torch.Tensor(points)\n",
    "        points, target = points.float().cuda(), target.long().cuda()\n",
    "        points = points.transpose(2, 1)\n",
    "\n",
    "        seg_pred, trans_feat = classifier(points)\n",
    "        pred_val = seg_pred.contiguous().cpu().data.numpy()\n",
    "        seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "        batch_label = target.cpu().data.numpy()\n",
    "        target = target.view(-1, 1)[:, 0]\n",
    "        loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "        loss_sum += loss\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum((pred_val == batch_label))\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "        tmp, _ = np.histogram(batch_label, range(NUM_CLASSES + 1))\n",
    "        labelweights += tmp\n",
    "\n",
    "        for l in range(NUM_CLASSES):\n",
    "            total_seen_class[l] += np.sum((batch_label == l))\n",
    "            total_correct_class[l] += np.sum((pred_val == l) & (batch_label == l))\n",
    "            total_iou_deno_class[l] += np.sum(((pred_val == l) | (batch_label == l)))\n",
    "\n",
    "    labelweights = labelweights.astype(np.float32) / np.sum(labelweights.astype(np.float32))\n",
    "    mIoU = np.mean(np.array(total_correct_class) / (np.array(total_iou_deno_class, dtype=np.float) + 1e-6))\n",
    "    print('eval mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    print('eval point avg class IoU: %f' % (mIoU))\n",
    "    print('eval point accuracy: %f' % (total_correct / float(total_seen)))\n",
    "    print('eval point avg class acc: %f' % (\n",
    "        np.mean(np.array(total_correct_class) / (np.array(total_seen_class, dtype=np.float) + 1e-6))))\n",
    "\n",
    "    iou_per_class_str = '------- IoU --------\\n'\n",
    "    for l in range(NUM_CLASSES):\n",
    "        iou_per_class_str += 'class %s weight: %.3f, IoU: %.3f \\n' % (\n",
    "            seg_label_to_cat[l] + ' ' * (14 - len(seg_label_to_cat[l])), labelweights[l - 1],\n",
    "            total_correct_class[l] / float(total_iou_deno_class[l]))\n",
    "\n",
    "    print(iou_per_class_str)\n",
    "    print('Eval mean loss: %f' % (loss_sum / num_batches))\n",
    "    print('Eval accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "    return mIoU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do require a GPU. Define the GPU value in a cluster of GPUs. By default it is 0 (a single GPU environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader Part:\n",
    "We choose S3DIS dataset for our implementation. The Stanford 3D Indoor Scene Dataset (S3DIS CVPR16) dataset contains 6 large-scale indoor areas with 271 rooms. Each point in the scene point cloud is annotated with one of the 13 semantic categories.\n",
    "\n",
    "References:\n",
    "Iro Armeni et. al. \"3D Semantic Parsing of Large-Scale Indoor Spaces\", CVPR, 2016\n",
    "\n",
    "\n",
    "The dataset and the related information is available at: http://buildingparser.stanford.edu/dataset.html\n",
    "\n",
    "\n",
    " <font color = 'red'> Note: We respect the data policy imposed by the author. So, we do not distribute the data or support of distribution. Kindly follow the data download link, read the conditions, fill-up the google form, and download the data from the generated link after you submit the google form. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../data/stanford_indoor3d/'\n",
    "NUM_CLASSES = 13\n",
    "NUM_POINT = args.npoint\n",
    "BATCH_SIZE = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 204/204 [00:19<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1233332 1.1800324 1.        2.238213  2.337216  2.3404622 1.7047739\n",
      " 2.0308683 1.8827153 3.8201103 1.7911378 2.7820194 1.343442 ]\n",
      "Totally 47576 samples in train set.\n",
      "start loading test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1457089  1.2112554  1.        10.023792   2.5368133  2.0141404\n",
      "  2.1255984  2.0063603  2.5044875  4.7404885  1.4208089  2.9067025\n",
      "  1.4772114]\n",
      "Totally 18822 samples in test set.\n",
      "The number of training data is: 47576\n",
      "The number of test data is: 18822\n"
     ]
    }
   ],
   "source": [
    "print(\"start loading training data ...\")\n",
    "TRAIN_DATASET = S3DISDataset(split='train', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "print(\"start loading test data ...\")\n",
    "TEST_DATASET = S3DISDataset(split='test', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "\n",
    "trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=10,\n",
    "                                                pin_memory=True, drop_last=True,\n",
    "                                                worker_init_fn=lambda x: np.random.seed(x + int(time.time())))\n",
    "testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=BATCH_SIZE, shuffle=False, num_workers=10,\n",
    "                                                pin_memory=True, drop_last=True)\n",
    "weights = torch.Tensor(TRAIN_DATASET.labelweights).cuda()\n",
    "\n",
    "print(\"The number of training data is: %d\" % len(TRAIN_DATASET))\n",
    "print(\"The number of test data is: %d\" % len(TEST_DATASET))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_model(\n",
       "  (feat): PointNetEncoder(\n",
       "    (stn): STN3d(\n",
       "      (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fstn): STNkd(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
       "  (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "  (conv4): Conv1d(128, 13, kernel_size=(1,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MODEL LOADING'''\n",
    "\n",
    "from models.pointnet_sem_seg import get_model, get_loss\n",
    "\n",
    "classifier = get_model(NUM_CLASSES).cuda()\n",
    "criterion = get_loss().cuda()\n",
    "classifier.apply(inplace_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Weights? Load it with Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model, starting training from scratch...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    checkpoint = torch.load('weights/best_model_segmentation.pth')\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('Use pretrain model')\n",
    "except:\n",
    "    print('No existing model, starting training from scratch...')\n",
    "    start_epoch = 0\n",
    "\n",
    "\n",
    "if args.optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(\n",
    "            classifier.parameters(),\n",
    "            lr=args.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=args.decay_rate\n",
    "        )\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(classifier.parameters(), lr=args.learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust Batchnorm momentum\n",
    "\n",
    "Momentum is the “lag” in learning mean and variance, so that noise due to mini-batch can be ignored. ... So high momentum will result in slow but steady learning (more lag) of the moving mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_momentum_adjust(m, momentum):\n",
    "    if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
    "        m.momentum = momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'> Hyperparameters </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_CLIP = 1e-5\n",
    "MOMENTUM_ORIGINAL = 0.1\n",
    "MOMENTUM_DECCAY = 0.5\n",
    "MOMENTUM_DECCAY_STEP = args.step_size\n",
    "\n",
    "global_epoch = 0\n",
    "best_iou = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Epoch 1 (1/32) ****\n",
      "Learning rate:0.001000\n",
      "BN momentum updated to: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                                                                 | 33/2973 [00:48<1:08:13,  1.39s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, args.epoch):\n",
    "    '''Train on chopped scenes'''\n",
    "    print('**** Epoch %d (%d/%s) ****' % (global_epoch + 1, epoch + 1, args.epoch))\n",
    "    lr = max(args.learning_rate * (args.lr_decay ** (epoch // args.step_size)), LEARNING_RATE_CLIP)\n",
    "    print('Learning rate:%f' % lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    momentum = MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // MOMENTUM_DECCAY_STEP))\n",
    "    if momentum < 0.01:\n",
    "        momentum = 0.01\n",
    "    print('BN momentum updated to: %f' % momentum)\n",
    "    classifier = classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
    "    num_batches = len(trainDataLoader)\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    classifier = classifier.train()\n",
    "\n",
    "    for i, (points, target) in tqdm(enumerate(trainDataLoader), total=len(trainDataLoader), smoothing=0.9):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        points = points.data.numpy()\n",
    "        points[:, :, :3] = rotate_point_cloud_z(points[:, :, :3])\n",
    "        points = torch.Tensor(points)\n",
    "        points, target = points.float().cuda(), target.long().cuda()\n",
    "        points = points.transpose(2, 1)\n",
    "\n",
    "        seg_pred, trans_feat = classifier(points)\n",
    "        seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
    "\n",
    "        batch_label = target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
    "        target = target.view(-1, 1)[:, 0]\n",
    "        loss = criterion(seg_pred, target, trans_feat, weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
    "        correct = np.sum(pred_choice == batch_label)\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "        loss_sum += loss\n",
    "    print('Training mean loss: %f' % (loss_sum / num_batches))\n",
    "    print('Training accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        mIoU = test(classifier.eval(), testDataLoader)\n",
    "\n",
    "        if mIoU >= best_iou:\n",
    "            best_iou = mIoU\n",
    "            print('Save model...')\n",
    "            savepath = 'weights' + '/best_model_segmentation.pth'\n",
    "            print('Saving at %s' % savepath)\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'class_avg_iou': mIoU,\n",
    "                'model_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, savepath)\n",
    "            print('Saving model....')\n",
    "        print('Best mIoU: %f' % best_iou)\n",
    "    global_epoch += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de1a49c4b984218e2f2a6199dd8f962c49bee168664be9f05afbb2365715af6a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
