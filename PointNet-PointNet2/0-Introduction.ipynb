{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Point Cloud and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does our data looks like?\n",
    "\n",
    "It is not important how we see the data, but it is the key factor for a neural network how it sees the incoming data. Does it mean something to the network? Does it represent some structure, symmetry, or geometry?\n",
    "\n",
    "Let us visualize, what our network is going to see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ModelNet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import required modules\n",
    "import torch\n",
    "from dataloaders.ModelNetDataLoader import ModelNetDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Donot change it if you want to visualize what is going to happen in the training case (1-Classification.ipynb)\n",
    "class Args:\n",
    "    '''PARAMETERS'''\n",
    "    use_cpu =False\n",
    "    gpu='0'\n",
    "    batch_size = 24\n",
    "    model='pointnet_cls'\n",
    "    num_category = 40\n",
    "    epoch=200\n",
    "    learning_rate=0.001\n",
    "    num_point=1024\n",
    "    optimizer='Adam'\n",
    "    log_dir = 'runs'\n",
    "    decay_rate=1e-4\n",
    "    use_normals=False\n",
    "    process_data=False\n",
    "    use_uniform_sample=False\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data is 9843\n"
     ]
    }
   ],
   "source": [
    "### ModelNet40 Dataset (we are going to use it in Classification)\n",
    "\n",
    "data_path = '../../data/modelnet40_normal_resampled/'\n",
    "\n",
    "train_dataset = ModelNetDataLoader(root=data_path, args=args,  split='train', process_data=args.process_data)\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=10, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification TrainDataLoader\n",
    "\n",
    "dataloader_iterator = iter(trainDataLoader)\n",
    "for i in range(1):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(trainDataLoader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1024, 3])\n",
      "torch.Size([24])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7739ceda88df4ae7b27952db77110614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(VBox(children=(HTML(value='<h3>color</h3>'), Dropdown(description='Colormap:', options={'B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "### Get the data \n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('ipygany')\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pointsss = data\n",
    "points = data.numpy()\n",
    "class_label = target\n",
    "classes = target.numpy()\n",
    "\n",
    "print(pointsss.shape)\n",
    "print(target.shape)\n",
    "\n",
    "\n",
    "### Visualize the data: Choose value of i < batch_size\n",
    "i = 19\n",
    "points = points[i]\n",
    "class_label = class_label[i]\n",
    "\n",
    "color = np.ones((points.shape[0], 1))\n",
    "color = color * classes\n",
    "\n",
    "data_plt = pv.PolyData(points)\n",
    "data_plt['color'] = color \n",
    "data_plt.plot()\n",
    "\n",
    "\n",
    "print(class_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. S3DIS Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloaders.S3DISDataLoader import S3DISDataset\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''PARAMETERS'''\n",
    "    gpu='0'\n",
    "    batch_size = 16\n",
    "    model='pointnet_sem_seg'\n",
    "    epoch=32\n",
    "    learning_rate=0.001\n",
    "    num_point=1024\n",
    "    optimizer='Adam'\n",
    "    log_dir = 'runs'\n",
    "    decay_rate=1e-4\n",
    "    npoint = 4096\n",
    "    step_size =10\n",
    "    lr_decay = 0.7\n",
    "    test_area=5\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 204/204 [00:21<00:00,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1233332 1.1800324 1.        2.238213  2.337216  2.3404622 1.7047739\n",
      " 2.0308683 1.8827153 3.8201103 1.7911378 2.7820194 1.343442 ]\n",
      "Totally 47576 samples in train set.\n",
      "The number of training data is: 47576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root = '../../data/stanford_indoor3d/'\n",
    "NUM_CLASSES = 13\n",
    "NUM_POINT = args.npoint\n",
    "BATCH_SIZE = args.batch_size\n",
    "\n",
    "print(\"start loading training data ...\")\n",
    "TRAIN_DATASET = S3DISDataset(split='train', data_root=root, num_point=NUM_POINT, test_area=args.test_area, block_size=1.0, sample_rate=1.0, transform=None)\n",
    "\n",
    "trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=10,\n",
    "                                                pin_memory=True, drop_last=True,\n",
    "                                                worker_init_fn=lambda x: np.random.seed(x + int(time.time())))\n",
    "print(\"The number of training data is: %d\" % len(TRAIN_DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(trainDataLoader)\n",
    "for i in range(1):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(trainDataLoader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes = \n",
    "0: Ceiling, 1: Floor, 2: Wall, 3: Beam, 4: Column, 5: Window, 6: Door, 7: Table, 8: Chair, 9: Sofa, 10: Bookcase, 11: Board, 12: Clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4096, 9])\n",
      "torch.Size([16, 4096])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8500b30d83442e9b11d1c2f3d0ac478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(VBox(children=(HTML(value='<h3></h3>'), Dropdown(description='Colormap:', options={'BrBG':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "### Get the data \n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('ipygany')\n",
    "import numpy as np\n",
    "\n",
    "pointsss = data\n",
    "points = data.numpy()\n",
    "points = points[:, :, 0:3]\n",
    "class_labels = target\n",
    "classes = class_labels.numpy()\n",
    "\n",
    "print(pointsss.shape)\n",
    "print(target.shape)\n",
    "\n",
    "### Visualize the data: Choose value of i < batch_size\n",
    "i = 1\n",
    "\n",
    "points = points[i]\n",
    "\n",
    "color = classes[i]\n",
    "\n",
    "data_plt = pv.PolyData(points)\n",
    "data_plt.points *= 10\n",
    "\n",
    "class_color = color \n",
    "\n",
    "\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_mesh(data_plt, scalars=class_color)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pointnet_sem_seg import get_model, get_loss\n",
    "\n",
    "classifier = get_model(NUM_CLASSES).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_model(\n",
      "  (feat): PointNetEncoder(\n",
      "    (stn): STN3d(\n",
      "      (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fstn): STNkd(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
      "  (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "  (conv3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "  (conv4): Conv1d(128, 13, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PointNet Total Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1024]             640\n",
      "       BatchNorm1d-2             [-1, 64, 1024]             128\n",
      "            Conv1d-3            [-1, 128, 1024]           8,320\n",
      "       BatchNorm1d-4            [-1, 128, 1024]             256\n",
      "            Conv1d-5           [-1, 1024, 1024]         132,096\n",
      "       BatchNorm1d-6           [-1, 1024, 1024]           2,048\n",
      "            Linear-7                  [-1, 512]         524,800\n",
      "       BatchNorm1d-8                  [-1, 512]           1,024\n",
      "            Linear-9                  [-1, 256]         131,328\n",
      "      BatchNorm1d-10                  [-1, 256]             512\n",
      "           Linear-11                    [-1, 9]           2,313\n",
      "            STN3d-12                 [-1, 3, 3]               0\n",
      "           Conv1d-13             [-1, 64, 1024]             640\n",
      "      BatchNorm1d-14             [-1, 64, 1024]             128\n",
      "           Conv1d-15             [-1, 64, 1024]           4,160\n",
      "      BatchNorm1d-16             [-1, 64, 1024]             128\n",
      "           Conv1d-17            [-1, 128, 1024]           8,320\n",
      "      BatchNorm1d-18            [-1, 128, 1024]             256\n",
      "           Conv1d-19           [-1, 1024, 1024]         132,096\n",
      "      BatchNorm1d-20           [-1, 1024, 1024]           2,048\n",
      "           Linear-21                  [-1, 512]         524,800\n",
      "      BatchNorm1d-22                  [-1, 512]           1,024\n",
      "           Linear-23                  [-1, 256]         131,328\n",
      "      BatchNorm1d-24                  [-1, 256]             512\n",
      "           Linear-25                 [-1, 4096]       1,052,672\n",
      "            STNkd-26               [-1, 64, 64]               0\n",
      "           Conv1d-27            [-1, 128, 1024]           8,320\n",
      "      BatchNorm1d-28            [-1, 128, 1024]             256\n",
      "           Conv1d-29           [-1, 1024, 1024]         132,096\n",
      "      BatchNorm1d-30           [-1, 1024, 1024]           2,048\n",
      "  PointNetEncoder-31  [[-1, 1088, 1024], [-1, 3, 3], [-1, 64, 64]]               0\n",
      "           Conv1d-32            [-1, 512, 1024]         557,568\n",
      "      BatchNorm1d-33            [-1, 512, 1024]           1,024\n",
      "           Conv1d-34            [-1, 256, 1024]         131,328\n",
      "      BatchNorm1d-35            [-1, 256, 1024]             512\n",
      "           Conv1d-36            [-1, 128, 1024]          32,896\n",
      "      BatchNorm1d-37            [-1, 128, 1024]             256\n",
      "           Conv1d-38             [-1, 13, 1024]           1,677\n",
      "================================================================\n",
      "Total params: 3,529,558\n",
      "Trainable params: 3,529,558\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 313415.19\n",
      "Params size (MB): 13.46\n",
      "Estimated Total Size (MB): 313428.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "classifier = classifier.cuda()\n",
    "summary(classifier, (9, 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Networks at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pointnet_utils import STN3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Net on Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = STN3d(channel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STN3d(\n",
      "  (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input T-Net total params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1024]             256\n",
      "       BatchNorm1d-2             [-1, 64, 1024]             128\n",
      "            Conv1d-3            [-1, 128, 1024]           8,320\n",
      "       BatchNorm1d-4            [-1, 128, 1024]             256\n",
      "            Conv1d-5           [-1, 1024, 1024]         132,096\n",
      "       BatchNorm1d-6           [-1, 1024, 1024]           2,048\n",
      "            Linear-7                  [-1, 512]         524,800\n",
      "       BatchNorm1d-8                  [-1, 512]           1,024\n",
      "            Linear-9                  [-1, 256]         131,328\n",
      "      BatchNorm1d-10                  [-1, 256]             512\n",
      "           Linear-11                    [-1, 9]           2,313\n",
      "================================================================\n",
      "Total params: 803,081\n",
      "Trainable params: 803,081\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 19.01\n",
      "Params size (MB): 3.06\n",
      "Estimated Total Size (MB): 22.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "trans_sum = trans.cuda()\n",
    "summary(trans_sum, (3,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Net on Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pointnet_utils import STNkd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = STNkd(k=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STNkd(\n",
      "  (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features T-Net total params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1024]           4,160\n",
      "       BatchNorm1d-2             [-1, 64, 1024]             128\n",
      "            Conv1d-3            [-1, 128, 1024]           8,320\n",
      "       BatchNorm1d-4            [-1, 128, 1024]             256\n",
      "            Conv1d-5           [-1, 1024, 1024]         132,096\n",
      "       BatchNorm1d-6           [-1, 1024, 1024]           2,048\n",
      "            Linear-7                  [-1, 512]         524,800\n",
      "       BatchNorm1d-8                  [-1, 512]           1,024\n",
      "            Linear-9                  [-1, 256]         131,328\n",
      "      BatchNorm1d-10                  [-1, 256]             512\n",
      "           Linear-11                 [-1, 4096]       1,052,672\n",
      "================================================================\n",
      "Total params: 1,857,344\n",
      "Trainable params: 1,857,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 19.04\n",
      "Params size (MB): 7.09\n",
      "Estimated Total Size (MB): 26.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "trans1_sum = trans1.cuda()\n",
    "summary(trans1_sum, (64,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PointNet Encoder (provides the Global Features)\n",
    "\n",
    "The encoder provides the global features from the point cloud. However this encoder doesnot consider the local features. The point features can be obtained from the features transform network.\n",
    "\n",
    "In the classification network, local features are ignored while in the segmentation network, the local features are concatenated with global features.\n",
    "\n",
    "PointNet encoder can be used for feature extraction and then these features can be used with traditional regressors or SVM classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pointnet_utils import PointNetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = PointNetEncoder(global_feat=True, feature_transform=False, channel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointNetEncoder(\n",
      "  (stn): STN3d(\n",
      "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 1024]             256\n",
      "       BatchNorm1d-2             [-1, 64, 1024]             128\n",
      "            Conv1d-3            [-1, 128, 1024]           8,320\n",
      "       BatchNorm1d-4            [-1, 128, 1024]             256\n",
      "            Conv1d-5           [-1, 1024, 1024]         132,096\n",
      "       BatchNorm1d-6           [-1, 1024, 1024]           2,048\n",
      "            Linear-7                  [-1, 512]         524,800\n",
      "       BatchNorm1d-8                  [-1, 512]           1,024\n",
      "            Linear-9                  [-1, 256]         131,328\n",
      "      BatchNorm1d-10                  [-1, 256]             512\n",
      "           Linear-11                    [-1, 9]           2,313\n",
      "            STN3d-12                 [-1, 3, 3]               0\n",
      "           Conv1d-13             [-1, 64, 1024]             256\n",
      "      BatchNorm1d-14             [-1, 64, 1024]             128\n",
      "           Conv1d-15            [-1, 128, 1024]           8,320\n",
      "      BatchNorm1d-16            [-1, 128, 1024]             256\n",
      "           Conv1d-17           [-1, 1024, 1024]         132,096\n",
      "      BatchNorm1d-18           [-1, 1024, 1024]           2,048\n",
      "================================================================\n",
      "Total params: 946,185\n",
      "Trainable params: 946,185\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 38.01\n",
      "Params size (MB): 3.61\n",
      "Estimated Total Size (MB): 41.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "encoder_sum = encoder.cuda()\n",
    "summary(encoder_sum, (3,1024))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50e1d202e66ca9d1bb86231cb6414771e783b64b793893d086f00fc72b4d7af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
